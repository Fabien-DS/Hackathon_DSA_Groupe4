{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f80477d",
   "metadata": {},
   "source": [
    "# Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c8fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d528cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze > /mnt/docker/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d356f07",
   "metadata": {},
   "source": [
    "## Utilisation du package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddaa501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette cellule permet d'appeler la version packagée du projet et d'en assurer le reload avant appel des fonctions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6513f10",
   "metadata": {},
   "source": [
    "# Configuration de l'experiment MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aaf422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/experiments'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1684a9e",
   "metadata": {},
   "source": [
    "# Outils par défaut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a37d4b",
   "metadata": {},
   "source": [
    "- [pandas_profiling](https://github.com/pandas-profiling/pandas-profiling) : EDA\n",
    "- [mljar](https://github.com/mljar/mljar-supervised) : auto ml\n",
    "- [interpretML](https://github.com/interpretml/interpret) : modèle nativelemnt interprétable\n",
    "- [explainerdashboard](https://github.com/oegedijk/explainerdashboard) : interprétation des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c599b",
   "metadata": {},
   "source": [
    "# Exemples d'utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b19aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "709d226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "housing = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pd.DataFrame(housing.data, columns=housing.feature_names),\n",
    "    housing.target,\n",
    "    test_size=0.25,\n",
    "    random_state=123,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44fe53d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "print(list(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ced4e5",
   "metadata": {},
   "source": [
    "## Exemple pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bff6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7f8c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = ProfileReport(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d7e452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c66b8f16bf4095af4e22ec2e96c576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4e6e3b08c9434f83a6905cb3f25c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da92b927910f4cf0a9f69d8f78b5871d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1a19648f9b41de9319fa89eb85b387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.to_file(output_file='pandas_profiling.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db2216",
   "metadata": {},
   "source": [
    "le code précédent a créé une page html, qu'il suffit d'ouvrir dans le browser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac459629",
   "metadata": {},
   "source": [
    "## Exemple ML-JAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "161f9dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: /mnt/auto_ml\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['Baseline', 'Linear', 'Decision Tree', 'Random Forest', 'Xgboost', 'Neural Network']\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble']\n",
      "* Step simple_algorithms will try to check up to 3 models\n",
      "1_Baseline rmse 8.974686 trained in 0.22 seconds\n",
      "2_DecisionTree rmse 6.086591 trained in 2.99 seconds\n",
      "3_Linear rmse 5.046435 trained in 2.14 seconds\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "4_Default_Xgboost rmse 4.23677 trained in 4.05 seconds\n",
      "5_Default_NeuralNetwork rmse 3.521359 trained in 0.4 seconds\n",
      "6_Default_RandomForest rmse 4.603043 trained in 1.73 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 3.504847 trained in 0.17 seconds\n",
      "AutoML fit time: 16.53 seconds\n",
      "AutoML best model: Ensemble\n",
      "Test MSE: 13.988403191076053\n"
     ]
    }
   ],
   "source": [
    "from supervised.automl import AutoML # mljar-supervised\n",
    "\n",
    "# train models with AutoML\n",
    "automl = AutoML(mode=\"Explain\", results_path='/mnt/auto_ml')\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "# compute the MSE on test data\n",
    "predictions = automl.predict(X_test)\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b283a17",
   "metadata": {},
   "source": [
    "## Exemple explainerdashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531b7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import explainerdashboard\n",
    "from explainerdashboard import RegressionExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e60ada0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: shap=='guess' so guessing for RandomForestRegressor shap='tree'...\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model)\n",
      "Changing class type to RandomForestRegressionExplainer...\n",
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating shap values...\n",
      "Calculating predictions...\n",
      "Calculating residuals...\n",
      "Calculating absolute residuals...\n",
      "Calculating dependencies...\n",
      "Calculating importances...\n",
      "Calculating ShadowDecTree for each individual decision tree...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from explainerdashboard import RegressionExplainer, ExplainerDashboard\n",
    "from explainerdashboard.datasets import titanic_survive, titanic_names, titanic_fare\n",
    "\n",
    "feature_descriptions = {\n",
    "    \"Sex\": \"Gender of passenger\",\n",
    "    \"Gender\": \"Gender of passenger\",\n",
    "    \"Deck\": \"The deck the passenger had their cabin on\",\n",
    "    \"PassengerClass\": \"The class of the ticket: 1st, 2nd or 3rd class\",\n",
    "    \"Fare\": \"The amount of money people paid\", \n",
    "    \"Embarked\": \"the port where the passenger boarded the Titanic. Either Southampton, Cherbourg or Queenstown\",\n",
    "    \"Age\": \"Age of the passenger\",\n",
    "    \"No_of_siblings_plus_spouses_on_board\": \"The sum of the number of siblings plus the number of spouses on board\",\n",
    "    \"No_of_parents_plus_children_on_board\" : \"The sum of the number of parents plus the number of children on board\",\n",
    "}\n",
    "\n",
    "X_train, y_train, X_test, y_test = titanic_fare()\n",
    "model = RandomForestRegressor().fit(X_train, y_train)\n",
    "\n",
    "explainer = RegressionExplainer(model, X_test, y_test, \n",
    "                                cats=['Deck', 'Embarked', 'Sex'],\n",
    "                                descriptions=feature_descriptions, \n",
    "                                units = \"$\", # defaults to \"\"\n",
    "                                )\n",
    "\n",
    "db = ExplainerDashboard(explainer,\n",
    "                        title=\"Exemple regression\", # defaults to \"Model Explainer\"\n",
    "                        shap_interaction=False, # you can switch off tabs with bools\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb896cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://localhost:8050\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-06 07:22:40,084 explainerdashboard.dashboards INFO Dash is running on http://127.0.0.1:8050/\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"explainerdashboard.dashboards\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-06 07:22:40,088 werkzeug INFO  * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "db.run(8050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd76e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to shut down dashboard on port 8050...\n",
      "Something seems to have failed: HTTPConnectionPool(host='localhost', port=8050): Max retries exceeded with url: /_shutdown_070574c4-998d-48df-b450-aa0160fde279 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8815cf5ac0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "db.terminate(8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81153e15",
   "metadata": {},
   "source": [
    "L'exemple suivant crée une appli sur le port (interne) 8050 qui est assigné par docker à la volée par la commande make-dev-start\n",
    "**ATTENTION** il faut récupérer l'adresse du port ouvert sur la machine par le commande `docker ps` pour le port interne 8050 (par ex 49155), puis aller ouvrir une fenêtre dans le browser sous `localhost:49155` (la valeur après les `:` étant à remplacée par la valeur du port lue dans le terminal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
