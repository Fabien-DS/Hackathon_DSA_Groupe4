{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa469261",
   "metadata": {},
   "source": [
    "# Modélisation Méthode 3 - `E[S]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9ff20",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b1256",
   "metadata": {},
   "source": [
    "### Import des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "f8502137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temps et fichiers\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "#Manipulation de données\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "#Modélisation\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import PoissonRegressor, GammaRegressor\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.metrics import mean_tweedie_deviance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, auc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import RandomizedSearchCV# the keys can be accessed with final_pipeline.get_params().keys()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Text\n",
    "import re\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "#Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "#Tracking d'expérience\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07431c0",
   "metadata": {},
   "source": [
    "### Utilisation du code du projet packagé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127d46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette cellule permet d'appeler la version packagée du projet et d'en assurer le reload avant appel des fonctions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8edfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d74e2b8",
   "metadata": {},
   "source": [
    "### Configuration de l'experiment MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd062894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/experiments'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4441b",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f1f3685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Importe les données\n",
    "\n",
    "#df\n",
    "df_merged =pd.read_parquet('/mnt/data/interim/df_merged.gzip')\n",
    "df_train=pd.read_parquet('/mnt/data/interim/df_train.gzip')\n",
    "df_val=pd.read_parquet('/mnt/data/interim/df_val.gzip')\n",
    "\n",
    "#X\n",
    "X_train=pd.read_parquet('/mnt/data/interim/X_train.gzip')\n",
    "X_val=pd.read_parquet('/mnt/data/interim/X_val.gzip')\n",
    "X_test=pd.read_parquet('/mnt/data/interim/X_test.gzip')\n",
    "\n",
    "#y\n",
    "y_train=pd.read_parquet('/mnt/data/interim/y_train.gzip')\n",
    "y_val=pd.read_parquet('/mnt/data/interim/y_val.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3def26",
   "metadata": {},
   "source": [
    "## Création du code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342991f",
   "metadata": {},
   "source": [
    "Laissé ici à titre de mémoire, ce code a ensuite été refactorisé dans le package du projet `hackathondsa_groupe4` pour plus de lisibilité entre les notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b253e2",
   "metadata": {},
   "source": [
    "### scores_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a35d5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_to_dict(score_df):\n",
    "    d = score_df['train'].to_dict()\n",
    "    d1 = dict(zip([x+'_train_' for x in  list(d.keys())], list(d.values())))\n",
    "    d = score_df['test'].to_dict()\n",
    "    d2 = dict(zip([x+'_test' for x in  list(d.keys())], list(d.values())))\n",
    "    d1.update(d2)\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7aa00",
   "metadata": {},
   "source": [
    "### score_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "aeaedc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_estimator(\n",
    "    estimator, X_train, X_test, df_train, df_test, target, weights,\n",
    "    tweedie_powers=None, use_weights=True\n",
    "):\n",
    "    \"\"\"Evaluate an estimator on train and test sets with different metrics\"\"\"\n",
    "\n",
    "    metrics = [\n",
    "        (\"D² explained\", None),   # Use default scorer if it exists\n",
    "        (\"mean abs. error\", mean_absolute_error),\n",
    "        (\"mean squared error\", mean_squared_error),\n",
    "    ]\n",
    "    if tweedie_powers:\n",
    "        metrics += [(\n",
    "            \"mean Tweedie dev p={:.4f}\".format(power),\n",
    "            partial(mean_tweedie_deviance, power=power)\n",
    "        ) for power in tweedie_powers]\n",
    "\n",
    "    res = []\n",
    "    for subset_label, X, df in [\n",
    "        (\"train\", X_train, df_train),\n",
    "        (\"test\", X_test, df_test),\n",
    "    ]:\n",
    "        y = df[target]\n",
    "        if use_weights:\n",
    "            _weights =  df[weights]\n",
    "        for score_label, metric in metrics:\n",
    "            if isinstance(estimator, tuple) and len(estimator) == 2:\n",
    "                # Score the model consisting of the product of frequency and\n",
    "                # severity models.\n",
    "                est_freq, est_sev = estimator\n",
    "                y_pred = est_freq.predict(X) * est_sev.predict(X)\n",
    "            else:\n",
    "                y_pred = estimator.predict(X)\n",
    "\n",
    "            if metric is None:\n",
    "                if not hasattr(estimator, \"score\"):\n",
    "                    continue\n",
    "                if use_weights:\n",
    "                    score = estimator.score(X, y, sample_weight=_weights)\n",
    "                else:\n",
    "                    score = estimator.score(X, y)\n",
    "            else:\n",
    "                if use_weights:\n",
    "                    score = metric(y, y_pred, sample_weight=_weights)\n",
    "                else:\n",
    "                    score = metric(y, y_pred)\n",
    "\n",
    "            res.append(\n",
    "                {\"subset\": subset_label, \"metric\": score_label, \"score\": score}\n",
    "            )\n",
    "\n",
    "    res = (\n",
    "        pd.DataFrame(res)\n",
    "        .set_index([\"metric\", \"subset\"])\n",
    "        .score.unstack(-1)\n",
    "        .round(4)\n",
    "        .loc[:, ['train', 'test']]\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb4e90",
   "metadata": {},
   "source": [
    "On commence par définir une fonction générique qui sera en capacité d'ajuster, optimiser et logger dans MLFlow les résultats de pipelines qui seront produits pour chaque essai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "706154dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_state_params(pipe, seed):\n",
    "    \"\"\"Crée un dictionnaire constitué de tous les paramètres 'random_state' d'un pipe et leur assigne une valeur unique\"\"\"\n",
    "    rs = re.findall(r\"[a-zA-Z\\_]+_random_state\", ' '.join(list(pipe.get_params().keys())))\n",
    "    rs=dict.fromkeys(rs, seed)\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e05f14",
   "metadata": {},
   "source": [
    "### train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "c20a3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPipelineMlFlow(mlf_XP, \n",
    "                        xp_name_iter, \n",
    "                        pipeline, \n",
    "                        X_train, y_train, X_test, y_test, \n",
    "                        target_col='Frequency', \n",
    "                        weight_col='exposure', \n",
    "                        use_weights=False, \n",
    "                        fixed_params={}, \n",
    "                        opti=False, iterable_params={}):\n",
    "    \"\"\"\n",
    "    Fonction générique permettant d'entrainer et d'optimiser un pipeline sklearn\n",
    "    Les paramètres et résultats sont stockés dans MLFlow\n",
    "    \"\"\"\n",
    "  \n",
    "    mlflow.set_experiment(mlf_XP)\n",
    "\n",
    "    with mlflow.start_run(run_name=xp_name_iter):\n",
    "        \n",
    "        start_time = time.monotonic()  \n",
    "        \n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        \n",
    "        # fit pipeline\n",
    "        pipeline.set_params(**fixed_params)\n",
    "        if not opti:\n",
    "            search = pipeline\n",
    "        else:\n",
    "            search = RandomizedSearchCV(pipeline, iterable_params)\n",
    "        \n",
    "        if use_weights:\n",
    "            search.fit(X_train, y_train[target_col], sample_weight=X_train[weight_col])\n",
    "        else:\n",
    "            search.fit(X_train, y_train[target_col])\n",
    "                \n",
    "        # get params\n",
    "        params_to_log = fixed_params #select initial params\n",
    "        if opti:\n",
    "            params_to_log.update(search.best_params_) #update for optimal solution\n",
    "        mlflow.log_params(params_to_log)\n",
    "        \n",
    "        # Evaluate metrics\n",
    "        y_pred=search.predict(X_test)\n",
    "        score = score_estimator(estimator=search, \n",
    "                                         X_train=X_train, \n",
    "                                         X_test=X_test, \n",
    "                                         df_train=y_train, \n",
    "                                         df_test=y_test, \n",
    "                                         target=target_col, \n",
    "                                         weights=weight_col,\n",
    "                                         use_weights=use_weights)\n",
    "        \n",
    "        # Print out metrics\n",
    "        print(xp_name_iter)\n",
    "        print(\"params:\" % params_to_log)\n",
    "        print(score)\n",
    "\n",
    "        mlflow.log_metrics(scores_to_dict(score))\n",
    "        mlflow.sklearn.log_model(pipeline, xp_name_iter)\n",
    "        \n",
    "        end_time = time.monotonic()\n",
    "        elapsed_time = timedelta(seconds=end_time - start_time)\n",
    "        print('elapsed time :', elapsed_time)\n",
    "        mlflow.set_tag(key=\"elapsed_time\", value=elapsed_time)   \n",
    "        \n",
    "    return search\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e03d2",
   "metadata": {},
   "source": [
    "La cellule suivante permet de créer des étapes de sélection de colonnes dans les Data Frame en entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2b231cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ba54f",
   "metadata": {},
   "source": [
    "## Essai pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f120848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_scale_transformer = make_pipeline(\n",
    "    FunctionTransformer(func=np.log),\n",
    "    StandardScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5555b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "column_trans = ColumnTransformer(\n",
    "    [\n",
    "        (\"binned_numeric\", KBinsDiscretizer(n_bins=10),\n",
    "            [\"VALEUR_DES_BIENS\"]),\n",
    "        (\"onehot_categorical\", OneHotEncoder(),\n",
    "            [\"FORMULE\", \"TYPE_RESIDENCE\", \"TYPE_RESIDENCE\", \"NB_PIECES\", \"SITUATION_JURIDIQUE\",'NIVEAU_JURIDIQUE','OBJETS_DE_VALEUR', 'ZONIER', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'NBSIN_TYPE2_AN1', 'NBSIN_TYPE2_AN2', 'NBSIN_TYPE2_AN3']),\n",
    "        (\"passthrough_numeric\", \"passthrough\",\n",
    "            [\"NB_PIECES\"]),\n",
    "        (\"log_scaled_numeric\", log_scale_transformer,\n",
    "            [])\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d0d4b",
   "metadata": {},
   "source": [
    "inspiration : https://towardsdatascience.com/pipeline-columntransformer-and-featureunion-explained-f5491f815f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dd0499ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical pipeline\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                     ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "# Define numerical pipeline\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', MinMaxScaler())])\n",
    "\n",
    "num_pipe_binned = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', KBinsDiscretizer(n_bins=10))])\n",
    "\n",
    "num_pipe_log = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', KBinsDiscretizer(n_bins=10))])\n",
    "\n",
    "\n",
    "# Fit column transformer to training data\n",
    "preprocessor = ColumnTransformer(transformers=[('cat', cat_pipe, [\"FORMULE\", \"TYPE_RESIDENCE\", \"SITUATION_JURIDIQUE\",'NIVEAU_JURIDIQUE','OBJETS_DE_VALEUR', 'ZONIER', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'NBSIN_TYPE2_AN1',  'NBSIN_TYPE2_AN3']),\n",
    "                                               ('num_binned', num_pipe_binned, [\"VALEUR_DES_BIENS\"])],remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7bddca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_GLM = Pipeline(\n",
    "    steps=[\n",
    "#        ('na', SimpleImputer(strategy='median')),\n",
    "#        ('preprocess', column_trans), #Sélection de la colonne à transformer (corpus)\n",
    "        ('preprocess', preprocessor), \n",
    "        (\"glm\", PoissonRegressor(max_iter=400))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8afb4d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'verbose',\n",
       " 'preprocess',\n",
       " 'glm',\n",
       " 'preprocess__n_jobs',\n",
       " 'preprocess__remainder',\n",
       " 'preprocess__sparse_threshold',\n",
       " 'preprocess__transformer_weights',\n",
       " 'preprocess__transformers',\n",
       " 'preprocess__verbose',\n",
       " 'preprocess__cat',\n",
       " 'preprocess__num_binned',\n",
       " 'preprocess__cat__memory',\n",
       " 'preprocess__cat__steps',\n",
       " 'preprocess__cat__verbose',\n",
       " 'preprocess__cat__imputer',\n",
       " 'preprocess__cat__encoder',\n",
       " 'preprocess__cat__imputer__add_indicator',\n",
       " 'preprocess__cat__imputer__copy',\n",
       " 'preprocess__cat__imputer__fill_value',\n",
       " 'preprocess__cat__imputer__missing_values',\n",
       " 'preprocess__cat__imputer__strategy',\n",
       " 'preprocess__cat__imputer__verbose',\n",
       " 'preprocess__cat__encoder__categories',\n",
       " 'preprocess__cat__encoder__drop',\n",
       " 'preprocess__cat__encoder__dtype',\n",
       " 'preprocess__cat__encoder__handle_unknown',\n",
       " 'preprocess__cat__encoder__sparse',\n",
       " 'preprocess__num_binned__memory',\n",
       " 'preprocess__num_binned__steps',\n",
       " 'preprocess__num_binned__verbose',\n",
       " 'preprocess__num_binned__imputer',\n",
       " 'preprocess__num_binned__scaler',\n",
       " 'preprocess__num_binned__imputer__add_indicator',\n",
       " 'preprocess__num_binned__imputer__copy',\n",
       " 'preprocess__num_binned__imputer__fill_value',\n",
       " 'preprocess__num_binned__imputer__missing_values',\n",
       " 'preprocess__num_binned__imputer__strategy',\n",
       " 'preprocess__num_binned__imputer__verbose',\n",
       " 'preprocess__num_binned__scaler__dtype',\n",
       " 'preprocess__num_binned__scaler__encode',\n",
       " 'preprocess__num_binned__scaler__n_bins',\n",
       " 'preprocess__num_binned__scaler__strategy',\n",
       " 'glm__alpha',\n",
       " 'glm__fit_intercept',\n",
       " 'glm__max_iter',\n",
       " 'glm__tol',\n",
       " 'glm__verbose',\n",
       " 'glm__warm_start']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipeline_GLM.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f82598c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini-GLM\n",
      "params:\n",
      "subset                    train         test\n",
      "metric                                      \n",
      "D² explained             0.0579       0.0294\n",
      "mean abs. error         61.3388      59.7598\n",
      "mean squared error  223222.3396  218523.5348\n",
      "elapsed time : 0:00:11.605138\n"
     ]
    }
   ],
   "source": [
    "trainPipelineMlFlow(\n",
    "    mlf_XP = 'Init',\n",
    "    xp_name_iter= \"Ini-GLM\", \n",
    "    pipeline=pipeline_GLM, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO', \n",
    "    fixed_params=random_state_params(pipeline_GLM,42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d80ec25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXPO                       0\n",
       "FORMULE                    0\n",
       "TYPE_RESIDENCE             0\n",
       "TYPE_HABITATION            0\n",
       "NB_PIECES               7458\n",
       "SITUATION_JURIDIQUE        0\n",
       "NIVEAU_JURIDIQUE           0\n",
       "VALEUR_DES_BIENS           0\n",
       "OBJETS_DE_VALEUR           0\n",
       "ZONIER                     0\n",
       "NBSIN_TYPE1_AN1            0\n",
       "NBSIN_TYPE1_AN3            0\n",
       "NBSIN_TYPE2_AN1            0\n",
       "NBSIN_TYPE2_AN2        13558\n",
       "NBSIN_TYPE2_AN3            0\n",
       "id                         0\n",
       "ANNEE                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "22a9de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini-GLM_alpha1e-4\n",
      "params:\n",
      "subset                   train         test\n",
      "metric                                     \n",
      "D² explained             0.058       0.0280\n",
      "mean abs. error         61.324      59.7487\n",
      "mean squared error  223221.747  218525.5891\n",
      "elapsed time : 0:00:11.671008\n"
     ]
    }
   ],
   "source": [
    "trainPipelineMlFlow(\n",
    "    mlf_XP = 'Init',\n",
    "    xp_name_iter= \"Ini-GLM_alpha1e-4\", \n",
    "    pipeline=pipeline_GLM, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO', \n",
    "    fixed_params={'glm__alpha':1e-4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc6f90",
   "metadata": {},
   "source": [
    "## Modélisation prime pure par Tweedie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e1ab9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_Tweedie = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocess', preprocessor), \n",
    "        (\"Tweedie\", TweedieRegressor(power=1.9, alpha=.1, max_iter=10000))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b6042d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini-Tweedie\n",
      "params:\n",
      "subset                    train         test\n",
      "metric                                      \n",
      "D² explained             0.0223       0.0171\n",
      "mean abs. error         60.0233      61.5289\n",
      "mean squared error  561186.4676  526904.9401\n",
      "elapsed time : 0:00:02.694281\n"
     ]
    }
   ],
   "source": [
    "trainPipelineMlFlow(\n",
    "    mlf_XP = 'Init',\n",
    "    xp_name_iter= \"Ini-Tweedie\", \n",
    "    pipeline=pipeline_Tweedie, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    target_col='PurePremium',\n",
    "    use_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9028d2",
   "metadata": {},
   "source": [
    "**ATTENTION**\n",
    "\n",
    "On doit créer une nouvelle classe qui supercherge pipeline pour assayer de faire passer les sample weights\n",
    "\n",
    "cf [erreur GitHub](https://github.com/scikit-learn/scikit-learn/issues/18159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bf27a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineSW(Pipeline):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        \"\"\"Fit and pass sample weights only to the last step\"\"\"\n",
    "        if sample_weight is not None:\n",
    "            kwargs = {self.steps[-1][0] + '__sample_weight': sample_weight}\n",
    "        else:\n",
    "            kwargs = {}\n",
    "        return super().fit(X, y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "71fe125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_Tweedie_SW = PipelineSW(\n",
    "    steps=[\n",
    "        ('preprocess', preprocessor), \n",
    "        (\"Tweedie\", TweedieRegressor(power=1.9, alpha=.1, max_iter=10000))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0d9ac6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'verbose',\n",
       " 'preprocess',\n",
       " 'Tweedie',\n",
       " 'preprocess__n_jobs',\n",
       " 'preprocess__remainder',\n",
       " 'preprocess__sparse_threshold',\n",
       " 'preprocess__transformer_weights',\n",
       " 'preprocess__transformers',\n",
       " 'preprocess__verbose',\n",
       " 'preprocess__cat',\n",
       " 'preprocess__num_binned',\n",
       " 'preprocess__cat__memory',\n",
       " 'preprocess__cat__steps',\n",
       " 'preprocess__cat__verbose',\n",
       " 'preprocess__cat__imputer',\n",
       " 'preprocess__cat__encoder',\n",
       " 'preprocess__cat__imputer__add_indicator',\n",
       " 'preprocess__cat__imputer__copy',\n",
       " 'preprocess__cat__imputer__fill_value',\n",
       " 'preprocess__cat__imputer__missing_values',\n",
       " 'preprocess__cat__imputer__strategy',\n",
       " 'preprocess__cat__imputer__verbose',\n",
       " 'preprocess__cat__encoder__categories',\n",
       " 'preprocess__cat__encoder__drop',\n",
       " 'preprocess__cat__encoder__dtype',\n",
       " 'preprocess__cat__encoder__handle_unknown',\n",
       " 'preprocess__cat__encoder__sparse',\n",
       " 'preprocess__num_binned__memory',\n",
       " 'preprocess__num_binned__steps',\n",
       " 'preprocess__num_binned__verbose',\n",
       " 'preprocess__num_binned__imputer',\n",
       " 'preprocess__num_binned__scaler',\n",
       " 'preprocess__num_binned__imputer__add_indicator',\n",
       " 'preprocess__num_binned__imputer__copy',\n",
       " 'preprocess__num_binned__imputer__fill_value',\n",
       " 'preprocess__num_binned__imputer__missing_values',\n",
       " 'preprocess__num_binned__imputer__strategy',\n",
       " 'preprocess__num_binned__imputer__verbose',\n",
       " 'preprocess__num_binned__scaler__dtype',\n",
       " 'preprocess__num_binned__scaler__encode',\n",
       " 'preprocess__num_binned__scaler__n_bins',\n",
       " 'preprocess__num_binned__scaler__strategy',\n",
       " 'Tweedie__alpha',\n",
       " 'Tweedie__fit_intercept',\n",
       " 'Tweedie__link',\n",
       " 'Tweedie__max_iter',\n",
       " 'Tweedie__power',\n",
       " 'Tweedie__tol',\n",
       " 'Tweedie__verbose',\n",
       " 'Tweedie__warm_start']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipeline_Tweedie_SW.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "16da984f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini-Tweedie-sampleWeight\n",
      "params:\n",
      "subset                    train         test\n",
      "metric                                      \n",
      "D² explained             0.0195       0.0156\n",
      "mean abs. error         56.0804      53.9778\n",
      "mean squared error  223595.3580  218201.8055\n",
      "elapsed time : 0:00:02.420781\n"
     ]
    }
   ],
   "source": [
    "model = trainPipelineMlFlow(\n",
    "    mlf_XP = 'Init',\n",
    "    xp_name_iter= \"Ini-Tweedie-sampleWeight\", \n",
    "    pipeline=pipeline_Tweedie_SW, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_val, \n",
    "    y_test=y_val, \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO',\n",
    "    use_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d813e58",
   "metadata": {},
   "source": [
    "### Opti Tweedie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ebac8c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Tweedie__power': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "30f18c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini-TweedieSW-optiPower-0\n",
      "params:\n",
      "subset                    train         test\n",
      "metric                                      \n",
      "D² explained             0.0017       0.0014\n",
      "mean abs. error         58.2854      56.1170\n",
      "mean squared error  223634.9062  218239.2274\n",
      "elapsed time : 0:00:02.702185\n"
     ]
    }
   ],
   "source": [
    "model = trainPipelineMlFlow(\n",
    "    mlf_XP = 'Init',\n",
    "    xp_name_iter= \"Ini-TweedieSW-optiPower-0\", \n",
    "    pipeline=pipeline_Tweedie_SW, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_val, \n",
    "    y_test=y_val, \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO',\n",
    "    use_weights=True,\n",
    "    fixed_params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058df51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "1586148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Tweedie__power': 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "eaf84445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini-TweedieSW-optiPower-1\n",
      "params:\n",
      "subset                    train         test\n",
      "metric                                      \n",
      "D² explained             0.0619       0.0441\n",
      "mean abs. error         58.0435      56.1713\n",
      "mean squared error  223267.8422  218175.6337\n",
      "elapsed time : 0:00:04.353207\n"
     ]
    }
   ],
   "source": [
    "model = trainPipelineMlFlow(\n",
    "    mlf_XP = 'Init',\n",
    "    xp_name_iter= \"Ini-TweedieSW-optiPower-1\", \n",
    "    pipeline=pipeline_Tweedie_SW, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_val, \n",
    "    y_test=y_val, \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO',\n",
    "    use_weights=True,\n",
    "    fixed_params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "4f7e94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Tweedie__power': 1.5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "d00380f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini-TweedieSW-optiPower-1.5\n",
      "params:\n",
      "subset                    train         test\n",
      "metric                                      \n",
      "D² explained             0.0715       0.0555\n",
      "mean abs. error         57.0900      55.0937\n",
      "mean squared error  223453.8596  218143.4718\n",
      "elapsed time : 0:00:03.113444\n"
     ]
    }
   ],
   "source": [
    "model = trainPipelineMlFlow(\n",
    "    mlf_XP = 'Init',\n",
    "    xp_name_iter= \"Ini-TweedieSW-optiPower-1.5\", \n",
    "    pipeline=pipeline_Tweedie_SW, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_val, \n",
    "    y_test=y_val, \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO',\n",
    "    use_weights=True,\n",
    "    fixed_params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "fed3181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Tweedie__power': 1.75\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "10904cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini-TweedieSW-optiPower-1.75\n",
      "params:\n",
      "subset                    train         test\n",
      "metric                                      \n",
      "D² explained             0.0447       0.0355\n",
      "mean abs. error         56.4804      54.4151\n",
      "mean squared error  223542.1760  218171.6343\n",
      "elapsed time : 0:00:02.757547\n"
     ]
    }
   ],
   "source": [
    "model = trainPipelineMlFlow(\n",
    "    mlf_XP = 'Init',\n",
    "    xp_name_iter= \"Ini-TweedieSW-optiPower-1.75\", \n",
    "    pipeline=pipeline_Tweedie_SW, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_val, \n",
    "    y_test=y_val, \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO',\n",
    "    use_weights=True,\n",
    "    fixed_params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "77ea329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Tweedie__power': 1.99\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "bae1b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini-TweedieSW-optiPower-1.99\n",
      "params:\n",
      "subset                    train         test\n",
      "metric                                      \n",
      "D² explained             0.0020       0.0016\n",
      "mean abs. error         55.8333      53.7116\n",
      "mean squared error  223628.7999  218224.7150\n",
      "elapsed time : 0:00:02.527945\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'Tweedie__power': 1.99\n",
    "}\n",
    "\n",
    "model = trainPipelineMlFlow(\n",
    "    mlf_XP = 'Init',\n",
    "    xp_name_iter= \"Ini-TweedieSW-optiPower-1.99\", \n",
    "    pipeline=pipeline_Tweedie_SW, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_val, \n",
    "    y_test=y_val, \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO',\n",
    "    use_weights=True,\n",
    "    fixed_params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6be470",
   "metadata": {},
   "source": [
    "## Enseignements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc734b8",
   "metadata": {},
   "source": [
    "La masse en 0 est beaucoup trop fort (98,3%) pour permettre une modélisation classique. On bascule sur l'option 2 : I(N>0)*E[S]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e4ded8",
   "metadata": {},
   "source": [
    "### On essaie de savoir si Tweedie peut déjà aider sur les sinistres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "def2aa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'Charge>0' does not exist. Creating a new experiment\n",
      "Chg-TweedieSW-optiPower-1.99\n",
      "params:\n",
      "subset                     train          test\n",
      "metric                                        \n",
      "D² explained        4.750000e-02  6.900000e-03\n",
      "mean abs. error     1.494872e+03  1.495566e+03\n",
      "mean squared error  9.068450e+06  9.489292e+06\n",
      "elapsed time : 0:00:00.135901\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'Tweedie__power': 1.99\n",
    "}\n",
    "\n",
    "model = trainPipelineMlFlow(\n",
    "    mlf_XP = 'Charge>0',\n",
    "    xp_name_iter= \"Chg-TweedieSW-optiPower-1.99\", \n",
    "    pipeline=pipeline_Tweedie_SW, \n",
    "    X_train=X_train[y_train['NB']>0], \n",
    "    y_train=y_train[y_train['NB']>0], \n",
    "    X_test=X_val[y_val['NB']>0], \n",
    "    y_test=y_val[y_val['NB']>0], \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO',\n",
    "    use_weights=True,\n",
    "    fixed_params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac6c5b2",
   "metadata": {},
   "source": [
    "### On passe à RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical pipeline\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                     ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "# Define numerical pipeline\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', MinMaxScaler())])\n",
    "\n",
    "num_pipe_binned = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', KBinsDiscretizer(n_bins=10))])\n",
    "\n",
    "num_pipe_log = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', KBinsDiscretizer(n_bins=10))])\n",
    "\n",
    "\n",
    "# Fit column transformer to training data\n",
    "preprocessor = ColumnTransformer(transformers=[('cat', cat_pipe, [\"FORMULE\", \"TYPE_RESIDENCE\", \"SITUATION_JURIDIQUE\",'NIVEAU_JURIDIQUE','OBJETS_DE_VALEUR', 'ZONIER', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'NBSIN_TYPE2_AN1',  'NBSIN_TYPE2_AN3']),\n",
    "                                               ('num_binned', num_pipe_binned, [\"VALEUR_DES_BIENS\"])],remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "5fad3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_RFR = PipelineSW(\n",
    "    steps=[\n",
    "        ('preprocess', preprocessor), \n",
    "        ('rf', RandomForestRegressor(random_state=42, n_estimators=100))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "bd62f00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'verbose',\n",
       " 'preprocess',\n",
       " 'rf',\n",
       " 'preprocess__n_jobs',\n",
       " 'preprocess__remainder',\n",
       " 'preprocess__sparse_threshold',\n",
       " 'preprocess__transformer_weights',\n",
       " 'preprocess__transformers',\n",
       " 'preprocess__verbose',\n",
       " 'preprocess__cat',\n",
       " 'preprocess__num_binned',\n",
       " 'preprocess__cat__memory',\n",
       " 'preprocess__cat__steps',\n",
       " 'preprocess__cat__verbose',\n",
       " 'preprocess__cat__imputer',\n",
       " 'preprocess__cat__encoder',\n",
       " 'preprocess__cat__imputer__add_indicator',\n",
       " 'preprocess__cat__imputer__copy',\n",
       " 'preprocess__cat__imputer__fill_value',\n",
       " 'preprocess__cat__imputer__missing_values',\n",
       " 'preprocess__cat__imputer__strategy',\n",
       " 'preprocess__cat__imputer__verbose',\n",
       " 'preprocess__cat__encoder__categories',\n",
       " 'preprocess__cat__encoder__drop',\n",
       " 'preprocess__cat__encoder__dtype',\n",
       " 'preprocess__cat__encoder__handle_unknown',\n",
       " 'preprocess__cat__encoder__sparse',\n",
       " 'preprocess__num_binned__memory',\n",
       " 'preprocess__num_binned__steps',\n",
       " 'preprocess__num_binned__verbose',\n",
       " 'preprocess__num_binned__imputer',\n",
       " 'preprocess__num_binned__scaler',\n",
       " 'preprocess__num_binned__imputer__add_indicator',\n",
       " 'preprocess__num_binned__imputer__copy',\n",
       " 'preprocess__num_binned__imputer__fill_value',\n",
       " 'preprocess__num_binned__imputer__missing_values',\n",
       " 'preprocess__num_binned__imputer__strategy',\n",
       " 'preprocess__num_binned__imputer__verbose',\n",
       " 'preprocess__num_binned__scaler__dtype',\n",
       " 'preprocess__num_binned__scaler__encode',\n",
       " 'preprocess__num_binned__scaler__n_bins',\n",
       " 'preprocess__num_binned__scaler__strategy',\n",
       " 'rf__bootstrap',\n",
       " 'rf__ccp_alpha',\n",
       " 'rf__criterion',\n",
       " 'rf__max_depth',\n",
       " 'rf__max_features',\n",
       " 'rf__max_leaf_nodes',\n",
       " 'rf__max_samples',\n",
       " 'rf__min_impurity_decrease',\n",
       " 'rf__min_impurity_split',\n",
       " 'rf__min_samples_leaf',\n",
       " 'rf__min_samples_split',\n",
       " 'rf__min_weight_fraction_leaf',\n",
       " 'rf__n_estimators',\n",
       " 'rf__n_jobs',\n",
       " 'rf__oob_score',\n",
       " 'rf__random_state',\n",
       " 'rf__verbose',\n",
       " 'rf__warm_start']"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipeline_RFR.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainPipelineMlFlow(\n",
    "    mlf_XP = 'Charge>0',\n",
    "    xp_name_iter= \"Chg-RFR\", \n",
    "    pipeline=pipeline_RFR, \n",
    "    X_train=X_train[y_train['NB']>0], \n",
    "    y_train=y_train[y_train['NB']>0], \n",
    "    X_test=X_val[y_val['NB']>0], \n",
    "    y_test=y_val[y_val['NB']>0], \n",
    "    target_col='PurePremium', \n",
    "    weight_col='EXPO',\n",
    "    use_weights=True,\n",
    "    fixed_params=params\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
